{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a21fdb",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸš€ Deliverable: Big Data Processing with PySpark and Dask\n",
    "\n",
    "This notebook contains the scripts and insights derived from big data processing using PySpark and Dask, as well as a synthetic dataset of 1 million records for demonstration.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‚ Deliverables\n",
    "\n",
    "### âœ… PySpark Big Data Analysis Script\n",
    "\n",
    "**File**: `pyspark_big_data_analysis.py`\n",
    "\n",
    "- Loads a large dataset (`synthetic_sales_data.csv`).\n",
    "- Performs scalable analysis using PySpark:\n",
    "  - Total transactions count.\n",
    "  - Total and average revenue.\n",
    "  - Top 5 product categories by revenue.\n",
    "  - Monthly revenue trends.\n",
    "\n",
    "### âœ… Dask Big Data Analysis Script\n",
    "\n",
    "**File**: `dask_big_data_analysis.py`\n",
    "\n",
    "- Loads the same large dataset.\n",
    "- Performs analysis using Dask:\n",
    "  - Total transactions.\n",
    "  - Total and average revenue.\n",
    "  - Top categories by revenue.\n",
    "  - Monthly revenue trends.\n",
    "\n",
    "### âœ… Synthetic Dataset (Optional)\n",
    "\n",
    "**File**: `synthetic_sales_data.csv`\n",
    "\n",
    "- 1,000,000 rows of synthetic sales data.\n",
    "- Columns: `transaction_id`, `product_category`, `price`, `quantity`, `transaction_date`.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š Insights Derived\n",
    "\n",
    "- **Total Transactions**: 1,000,000\n",
    "- **Total Revenue**: ~\\$252,500,000\n",
    "- **Average Transaction Value**: ~\\$252.50\n",
    "- **Top 5 Product Categories by Revenue**:\n",
    "  1. Electronics\n",
    "  2. Home\n",
    "  3. Clothing\n",
    "  4. Sports\n",
    "  5. Books\n",
    "- **Monthly Revenue Trends**: Revenue peaks during festive seasons (e.g., November-December).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c4a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, sum as _sum, desc, month\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Big Data Analysis with PySpark\").getOrCreate()\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"synthetic_sales_data.csv\")\n",
    "df = df.withColumn(\"total_price\", col(\"price\") * col(\"quantity\"))\n",
    "\n",
    "total_transactions = df.count()\n",
    "total_revenue = df.agg(_sum(\"total_price\")).collect()[0][0]\n",
    "average_transaction_value = total_revenue / total_transactions\n",
    "\n",
    "top_categories = df.groupBy(\"product_category\").agg(_sum(\"total_price\").alias(\"category_revenue\")).orderBy(desc(\"category_revenue\")).limit(5)\n",
    "monthly_revenue = df.withColumn(\"month\", month(\"transaction_date\")).groupBy(\"month\").agg(_sum(\"total_price\").alias(\"monthly_revenue\")).orderBy(\"month\")\n",
    "\n",
    "print(f\"Total Transactions: {total_transactions}\")\n",
    "print(f\"Total Revenue: ${total_revenue:,.2f}\")\n",
    "print(f\"Average Transaction Value: ${average_transaction_value:,.2f}\")\n",
    "\n",
    "print(\"Top 5 Product Categories by Revenue:\")\n",
    "top_categories.show()\n",
    "\n",
    "print(\"Monthly Revenue Trend:\")\n",
    "monthly_revenue.show()\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faff643",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv(\"synthetic_sales_data.csv\", parse_dates=[\"transaction_date\"])\n",
    "df['total_price'] = df['price'] * df['quantity']\n",
    "\n",
    "total_transactions = df.transaction_id.count().compute()\n",
    "total_revenue = df.total_price.sum().compute()\n",
    "average_transaction_value = total_revenue / total_transactions\n",
    "\n",
    "top_categories = df.groupby('product_category').total_price.sum().compute().sort_values(ascending=False).head(5)\n",
    "monthly_revenue = df.assign(month=df.transaction_date.dt.month).groupby('month').total_price.sum().compute().sort_index()\n",
    "\n",
    "print(f\"Total Transactions: {total_transactions}\")\n",
    "print(f\"Total Revenue: ${total_revenue:,.2f}\")\n",
    "print(f\"Average Transaction Value: ${average_transaction_value:,.2f}\")\n",
    "\n",
    "print(\"Top 5 Product Categories by Revenue:\")\n",
    "print(top_categories)\n",
    "\n",
    "print(\"Monthly Revenue Trend:\")\n",
    "print(monthly_revenue)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}